<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>å¼ºåŒ–å­¦ä¹ ç¬”è®°</title>
    <link href="/2020/08/20/RLbook_001/"/>
    <url>/2020/08/20/RLbook_001/</url>
    
    <content type="html"><![CDATA[<blockquote><p><em>Reinforcement Learning An Introduction</em> - Richard Sutton &amp; Andrew Barto</p></blockquote><h1 id="k-è‡‚è€è™æœºï¼ˆA-k-armed-Bandit-Problemï¼‰"><a href="#k-è‡‚è€è™æœºï¼ˆA-k-armed-Bandit-Problemï¼‰" class="headerlink" title="$k$è‡‚è€è™æœºï¼ˆA $k$-armed Bandit Problemï¼‰"></a>$k$è‡‚è€è™æœºï¼ˆA $k$-armed Bandit Problemï¼‰</h1><p>$k$è‡‚è€è™æœºé—®é¢˜ä¸­ï¼Œé€‰æ‹©æ¯ä¸ªåŠ¨ä½œéƒ½ä¼šæœ‰ç›¸åº”çš„æœŸæœ›æ”¶ç›Šï¼Œç§°ä¸ºè¿™ä¸ªåŠ¨ä½œçš„ä»·å€¼ï¼ˆvalueï¼‰ã€‚<br>è®°æ—¶åˆ»$t$çš„åŠ¨ä½œä¸º$A<em>t$ï¼Œç›¸åº”çš„æ”¶ç›Šä¸º$R_t$ï¼Œä»»æ„åŠ¨ä½œ$a$çš„ä»·å€¼ä¸º$q</em>*(a)$ï¼Œé‚£ä¹ˆé€‰æ‹©$a$æ—¶çš„æœŸæœ›æ”¶ç›Šä¸º</p><script type="math/tex; mode=display">q_*(a) = \mathbb{E} \left[R_t | A_t = a\right]</script><p>ç°å®ä¸­ï¼Œæˆ‘ä»¬ä¸çŸ¥é“å®é™…çš„åŠ¨ä½œä»·å€¼ï¼Œå¦åˆ™åªè¦æ¯æ¬¡æŒ‘ä»·å€¼æœ€é«˜çš„åŠ¨ä½œå°±å¯ä»¥äº†ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä¼°è®¡è¿™äº›åŠ¨ä½œçš„ä»·å€¼ï¼Œè®°ä¸º$Q_t(a)$ã€‚</p><p>å¦‚æœæ¯æ¬¡å†³ç­–æ—¶ï¼Œæˆ‘ä»¬éƒ½é€‰æ‹©ä¼°è®¡ä»·å€¼æœ€å¤§çš„åŠ¨ä½œï¼Œåˆ™ç§°è¿™æ˜¯è´ªå©ªçš„ï¼ˆgreedyï¼‰ã€‚è´ªå©ªç­–ç•¥åœ¨çŸ­æœŸå†…å¯ä»¥è·å¾—è¾ƒå¤§çš„æ”¶ç›Šï¼Œä½†é•¿æœŸçœ‹æ¥è¿™å¸¸å¸¸æ˜¯çŸ­è§†çš„ã€‚å› æ­¤æœ‰å¿…è¦é€‚æ—¶åœ°é€‰å–ä¸€äº›éè´ªå©ªçš„åŠ¨ä½œã€‚ä¸Šè¿°çš„è´ªå©ªè¡Œä¸ºåˆç§°ä¸ºexploitationï¼Œè€Œéè´ªå©ªè¡Œä¸ºåˆç§°ä¸ºexplorationã€‚ä¸ºäº†èƒ½å¤Ÿè¿›è¡Œæœ€ä¼˜çš„å†³ç­–ï¼Œå¿…é¡»å¯¹äºŒè€…è¿›è¡Œæƒè¡¡ã€‚</p><h1 id="åŠ¨ä½œä»·å€¼ï¼ˆAction-value-Methodsï¼‰"><a href="#åŠ¨ä½œä»·å€¼ï¼ˆAction-value-Methodsï¼‰" class="headerlink" title="åŠ¨ä½œä»·å€¼ï¼ˆAction-value Methodsï¼‰"></a>åŠ¨ä½œä»·å€¼ï¼ˆAction-value Methodsï¼‰</h1><p>åŠ¨ä½œçš„ä»·å€¼æ˜¯é€‰æ‹©å®ƒè·å–çš„å¹³å‡å›æŠ¥ï¼Œå› æ­¤è¦ä¼°è®¡ä¸€ä¸ªåŠ¨ä½œçš„ä»·å€¼ï¼Œè‡ªç„¶å¯ä»¥å¯¹å†å²æ”¶ç›Šæ±‚å¹³å‡ï¼Œ</p><script type="math/tex; mode=display">Q_t(a) = \frac{tæ—¶åˆ»å‰åŠ¨ä½œaçš„æ€»æ”¶ç›Š}{tæ—¶åˆ»å‰é€‰æ‹©åŠ¨ä½œaçš„æ€»æ¬¡æ•°} =\frac{\sum_{i=1}^{t-1} R_i \cdot \mathbb{I}_{A_i=a}}{\sum_{i=1}^{t-1} \mathbb{I}_{A_i=a}}</script><p>æ ¹æ®å¤§æ•°å®šå¾‹ï¼Œ<script type="math/tex">Q_t (a)</script>æ”¶æ•›äº<script type="math/tex">q_*(a)</script>ã€‚</p><p><strong>è´ªå©ªè¡Œä¸º</strong>ï¼š</p><script type="math/tex; mode=display">A_t = \underset{a}{\text{arg max}} Q_t(a)</script><p><strong>$\varepsilon$-<em>greedy</em></strong>ï¼šå¤§å¤šæ•°æ—¶å€™é€‰å–è´ªå©ªåŠ¨ä½œï¼Œæ¯éš”ä¸€æ®µæ—¶é—´ï¼Œä¾‹å¦‚ä»¥æ¦‚ç‡$\varepsilon$ï¼Œç­‰æ¦‚ç‡åœ°éšæœºä»æ‰€æœ‰åŠ¨ä½œä¸­é€‰æ‹©ä¸€ä¸ªï¼Œä¸è€ƒè™‘ä¼°è®¡ä»·å€¼ã€‚</p><p>$\varepsilon$-<em>greedy</em>çš„ä¼˜åŠ¿åœ¨äºï¼Œå½“é‡‡æ ·æ¬¡æ•°è¶‹è¿‘äºæ— ç©·æ—¶ï¼Œå¯ä»¥ç¡®ä¿<script type="math/tex">Q_t (a)</script>æ”¶æ•›åˆ°<script type="math/tex">q_*(a)</script>ã€‚</p><blockquote><p><strong>Exercise 2.1</strong><br>In $\varepsilon$-<em>greedy</em> action selection, for the case of two actions and $\varepsilon = 0.5$, what is the probability that the greedy action is selected?</p></blockquote><p><strong>è§£ç­”ï¼š</strong></p><script type="math/tex; mode=display">\begin{align}P(\text{select greedy}) = &P(\text{select greedy}|\text{exploitation}) P(\text{exploitation}) + \\ &P(\text{select greedy}|\text{exploration}) P(\text{exploration}) \\=&1 \cdot (1 - \varepsilon) + \frac{1}{k} \varepsilon \\=&1 - \frac{k-1}{k} \varepsilon\end{align}</script><p>éœ€è¦æ³¨æ„å³ä½¿æ˜¯åœ¨explorationæ­¥éª¤ï¼Œç”±äºæ˜¯éšæœºé€‰æ‹©åŠ¨ä½œï¼Œå› æ­¤ä»ç„¶æœ‰å¯èƒ½é€‰æ‹©åˆ°è´ªå©ªçš„åŠ¨ä½œã€‚</p><h1 id="10è‡‚è€è™æœº"><a href="#10è‡‚è€è™æœº" class="headerlink" title="10è‡‚è€è™æœº"></a>10è‡‚è€è™æœº</h1><p>ä¸€ä¸ªå°ä¾‹å­ğŸŒ°ï¼ŒåŒ…å«2000ä¸ªéšæœºç”Ÿæˆçš„10è‡‚è€è™æœºé—®é¢˜ï¼Œå¯¹äºæ¯ä¸ªè€è™æœºï¼ŒåŠ¨ä½œçš„ä»·å€¼ä»ä¸€ä¸ªæ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·è·å¾—ã€‚åœ¨æ¯ä¸ªè€è™æœºçš„å®éªŒä¸­ï¼Œè¿è¡Œ1000ä¸ªæ—¶é—´æ­¥ï¼Œé‡å¤2000æ¬¡å®éªŒï¼Œå¯ä»¥è·çŸ¥ç®—æ³•çš„å¹³å‡æ€§èƒ½ã€‚åŠ¨ä½œçš„ä»·å€¼åˆ™ä½¿ç”¨æœ€ç®€å•çš„é‡‡æ ·å¹³å‡æ³•ï¼‰ï¼ˆåˆå§‹ä¼°è®¡å€¼ä¸º0ï¼‰ã€‚<br>æ ¹æ®å®éªŒç»“æœï¼Œåœ¨è¾ƒæ—©çš„æ—¶é—´æ­¥ï¼Œè´ªå©ªæ–¹æ³•çš„å¹³å‡æ”¶ç›Šæå‡è¾ƒå¿«ï¼Œä½†å¾ˆå¿«å°±è¿›å…¥å¹³å°æœŸï¼›è€Œéè´ªå©ªæ–¹æ³•åˆ™èƒ½å¤Ÿç»§ç»­æå‡ï¼Œå¹³å‡æ”¶ç›Šé€æ¸æ˜¾è‘—è¶…è¿‡è´ªå©ªæ–¹æ³•ã€‚</p><p>$\varepsilon$-<em>greedy</em>çš„ä¼˜åŠ¿ä¹Ÿä¸å…·ä½“ä»»åŠ¡æœ‰å…³ï¼Œå¦‚æœæ”¶ç›Šå€¼çš„å™ªå£°è¾ƒå¤§ï¼Œå°±éœ€è¦æ›´å¤šçš„explorationæ‰èƒ½è·å–æœ€ä¼˜åŠ¨ä½œï¼Œ$\varepsilon$-<em>greedy</em>çš„ä¼˜åŠ¿ä¹Ÿæ›´å¤§ï¼›å¦‚æœæ”¶ç›Šå€¼æ²¡æœ‰å™ªå£°ï¼Œé‚£ä¹ˆè´ªå©ªæ–¹æ³•å¾ˆå¿«å°±èƒ½æ‰¾åˆ°æœ€ä¼˜åŠ¨ä½œã€‚å¦‚æœä»»åŠ¡æ˜¯éå¹³ç¨³çš„ï¼Œä¹Ÿå°±æ˜¯åŠ¨ä½œä»·å€¼ä¼šéšæ—¶é—´å‘ç”Ÿå˜åŒ–ï¼Œé‚£ä¹ˆexplorationå°±æ˜¯ä¸€ä¸ªå¿…è¦çš„æ“ä½œã€‚</p><blockquote><p><strong>Exercise 2.2</strong><br>Consider a $k$-armed bandit problem with $k = 4$ actions, denoted 1, 2, 3, and 4. Consider applying to this problem a bandit algorithm using $\varepsilon$-greedy action selection, sample-average action-value estimates, and initial estimates of $Q_1(a) = 0$, for all $a$. Suppose the initial sequence of actions and rewards is $A_1 = 1, R_1 = -1, A_2 = 2, R_2 = 1, A_3 = 2, R_3 = -2, A_4 = 2, R_4 = 2, A_5 = 3, R_5 = 0$. On some of these time steps the $\varepsilon$ case may have occurred, causing an action to be selected at random. On which time steps did this definitely occur? On which time steps could this possibly have occurred?</p></blockquote><p><strong>è§£ç­”ï¼š</strong></p><div class="table-container"><table><thead><tr><th>æ—¶é—´æ­¥</th><th>æœ€ä¼˜åŠ¨ä½œ</th><th>åŠ¨ä½œ</th></tr></thead><tbody><tr><td>1</td><td>1,2,3,4</td><td>1</td></tr><tr><td>2</td><td>2,3,4</td><td>2</td></tr><tr><td>3</td><td>2</td><td>2</td></tr><tr><td>4</td><td>3,4</td><td>2</td></tr><tr><td>5</td><td>2</td><td>3</td></tr></tbody></table></div><p>ä¸Šè¡¨ç¬¬äºŒåˆ—æ˜¯æ¯ä¸ªæ—¶é—´æ­¥å†³ç­–å‰ï¼Œä¼°è®¡ä»·å€¼æœ€é«˜çš„åŠ¨ä½œé›†åˆã€‚<br>å¦‚æœé€‰æ‹©çš„åŠ¨ä½œä¸åœ¨æœ€ä¼˜åŠ¨ä½œé›†åˆä¸­ï¼Œé‚£ä¹ˆå¿…è¦å‘ç”Ÿäº†explorationã€‚<br>å› æ­¤ï¼Œç¬¬4ã€5æ­¥å¿…ç„¶æ˜¯explorationï¼Œä½†å…¶å®ƒä¹Ÿéƒ½æœ‰å¯èƒ½æ˜¯explorationã€‚</p><blockquote><p><strong>Exercise 2.3</strong><br>In the comparison shown in Figure 2.2, which method will perform best in the long run in terms of cumulative reward and probability of selecting the best action? How much better will it be? Express your answer quantitatively.<br>data:image/png;base64,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" data-original="" srcset="/img/loading.gif<img src="" alt=""></p></blockquote><p><strong>è§£ç­”ï¼š</strong><br>$\varepsilon=0.01$çš„æ–¹æ³•ä¼šå–å¾—æœ€å¤§çš„æ”¶ç›Šã€‚</p>]]></content>
    
    
    
    <tags>
      
      <tag>reinforcement learning, machine learning, note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ä¸­æ–‡æµ‹è¯•</title>
    <link href="/2020/07/17/test-math/"/>
    <url>/2020/07/17/test-math/</url>
    
    <content type="html"><![CDATA[<script type="math/tex; mode=display">a+b=c</script><blockquote><p>æ»šæ»šé•¿æ±Ÿä¸œé€æ°´ï¼ŒæµªèŠ±æ·˜å°½è‹±é›„ã€‚</p></blockquote><p><strong>è¿™ä¹Ÿæ˜¯</strong>ç¥å¥‡çš„<em>ä¸€å¤©</em>å‘¢ã€‚</p>]]></content>
    
    
    
    <tags>
      
      <tag>test</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>æ–‡ç« æµ‹è¯•</title>
    <link href="/2020/07/09/test-article/"/>
    <url>/2020/07/09/test-article/</url>
    
    <content type="html"><![CDATA[<h1 id="Get-start"><a href="#Get-start" class="headerlink" title="Get start!!!"></a>Get start!!!</h1><p>ä¸ºä»€ä¹ˆä¸æ˜¾ç¤ºå‘¢ï¼Ÿ<br>çœŸå¥‡æ€ªã€‚</p><p>Balalalallalalalalalala.</p><h1 id="First"><a href="#First" class="headerlink" title="First"></a>First</h1><p>This is a <strong>serious</strong> problem.</p><blockquote><p>Hand in hand.</p></blockquote><ul><li>Mango</li><li>Water</li><li><em>Banana</em></li></ul><h1 id="Start-again"><a href="#Start-again" class="headerlink" title="Start again"></a>Start again</h1><h2 id="Warm-up"><a href="#Warm-up" class="headerlink" title="Warm up"></a>Warm up</h2><p>$\mathop{x} \limits_a^b$</p><script type="math/tex; mode=display">\int_{i=1}^n x^2 \text{d}x</script><script type="math/tex; mode=display">\int_{i=1}^n x^2 \text{d}x</script><script type="math/tex; mode=display">\begin{equation}\int_{i=1}^n x^2 \text{d}x\end{equation}</script><script type="math/tex; mode=display">e_r(x)=\frac{x-x}{x^{*}}</script><script type="math/tex; mode=display">\min_{\mathbf{w},b} \frac{1}{2} \Vert \mathbf{w} \Vert^2 \quad s.t. \quad y_i(\mathbf{w}^T\phi(\mathbf{x})+b) \geq 1, \quad  i=1,2,...,m\qquad(9)</script><script type="math/tex; mode=display">\underset{a}{\text{arg max}}</script><script type="math/tex; mode=display">e\left ( x^{*} \right ) = x - x^{*}x = a_0 + \frac{1}{a_1 +\sqrt{a^2+b^2} \frac{1}{a_2 + \frac{1}{a_3 + a_4}}}\sqrt{a^2+b^2}</script><script type="math/tex; mode=display">f_n=f_{n-1}+f_{n-2}</script><script type="math/tex; mode=display">f_n</script><script type="math/tex; mode=display">f_1</script><script type="math/tex; mode=display">f^n</script><script type="math/tex; mode=display">f^1</script><script type="math/tex; mode=display">f</script><p>Then,</p><script type="math/tex; mode=display">\begin{aligned}a + b &= c\\\mathbf{x} &\sim \mathcal{N}(0, 1)\end{aligned}</script><script type="math/tex; mode=display">a + b = c</script><p>$a + b = c$</p><p>This equation <script type="math/tex">\cos 2\theta = \cos^2 \theta - \sin^2 \theta =  2 \cos^2 \theta - 1</script> is inline.</p><script type="math/tex; mode=display">\begin{aligned}\dot{x} & = \sigma(y-x) \\\dot{y} & = \rho x - y - xz \\\dot{z} & = -\beta z + xy\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}\dot{x} & = \sigma(y-x) \\\dot{y} & = \rho x - y - xz \\\dot{z} & = -\beta z + xy\end{aligned}</script><h2 id="Keyboard"><a href="#Keyboard" class="headerlink" title="Keyboard"></a>Keyboard</h2><pre><code class="hljs python"><span class="hljs-keyword">import</span> python <span class="hljs-keyword">as</span> pd<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> npdf = pd.DataFrame(np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">100</span>, (<span class="hljs-number">50</span>, <span class="hljs-number">3</span>)))print(df)</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>test</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/07/09/hello-world/"/>
    <url>/2020/07/09/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
